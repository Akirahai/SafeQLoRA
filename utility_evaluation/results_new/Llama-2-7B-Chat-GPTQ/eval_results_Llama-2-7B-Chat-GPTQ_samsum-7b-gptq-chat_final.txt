Evaluation Results for model: Llama-2-7B-Chat-GPTQ_samsum-7b-gptq-chat_final on samsum test dataset
Base model: TheBloke/Llama-2-7B-Chat-GPTQ
LoRA adapter: None
LoRA adapter name: samsum_adapter
Average Rouge F1 Score: 0.4476496341020173
Total samples evaluated: 0
Batch size used: 64
